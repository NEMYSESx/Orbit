version: "3.8"

services:
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - chat-app-network

  tika:
    image: apache/tika:latest
    container_name: tika
    ports:
      - "9998:9998"
    networks:
      - chat-app-network

  kafka:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"
      KAFKA_LISTENERS: "PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    networks:
      - chat-app-network

  ingestion-pipeline:
    build:
      context: ./apps/ingestion-pipeline
      dockerfile: Dockerfile
    image: ingestion-pipeline:latest
    container_name: ingestion-pipeline
    ports:
      - "3001:3001"
    depends_on:
      - kafka
      - tika
    restart: unless-stopped
    networks:
      - chat-app-network

  embedding-pipeline:
    build:
      context: ./apps/embedding-pipeline
      dockerfile: Dockerfile
    image: embedding-pipeline:latest
    container_name: embedding-pipeline
    ports:
      - "3002:3002"
    depends_on:
      - kafka
      - ingestion-pipeline
    networks:
      - chat-app-network
    restart: unless-stopped

  rag-api:
    build:
      context: ./apps/rag
      dockerfile: Dockerfile
    image: rag-api:latest
    container_name: rag-api
    ports:
      - "8000:8000"
    depends_on:
      embedding-pipeline:
        condition: service_started
      redis:
        condition: service_healthy
    restart: unless-stopped
    environment:
      - QDRANT_URL=https://bad7e720-f630-4fe4-a36d-9e7f85ae7503.europe-west3-0.gcp.cloud.qdrant.io:6333
      - QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.o0-1435PBNpbvrb4AvciyNGW9XhYQc8SmP76Dcmk7s0
      - COLLECTION_SIMILARITY_THRESHOLD=0.7
      - CREATE_COLLECTIONS_DYNAMICALLY=true
      - EMBEDDING_MODEL=models/text-embedding-004
      - EMBEDDING_DIMENSIONALITY=768
      - LLM_MODEL=gemini-2.0-flash
      - GEMINI_API_KEY=AIzaSyByCUsepBOtNC4xt1T30KBZKDrDScQArHo
      - CONNECTION_TIMEOUT=15
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
    networks:
      - chat-app-network

  chat-backend:
    build:
      context: ./apps/chat/backend
      dockerfile: Dockerfile
    image: chat-backend:latest
    container_name: chat-backend
    ports:
      - "8080:8080"
    depends_on:
      redis:
        condition: service_healthy
      rag-api:
        condition: service_started
    environment:
      - INGESTION_URL=http://ingestion-pipeline:3001
      - FRONTEND_URL=http://chat-frontend:5173
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - RAG_API_URL=http://rag-api:8000
    restart: unless-stopped
    networks:
      - chat-app-network

  chat-frontend:
    build:
      context: ./apps/chat/frontend
      dockerfile: Dockerfile
    image: chat-frontend:latest
    container_name: chat-frontend
    ports:
      - "5173:5173"
    depends_on:
      - chat-backend
      - ingestion-pipeline
      - rag-api
    environment:
      - VITE_BACKEND_URL=http://localhost:8080
      - VITE_API_URL=http://localhost:8000
    restart: unless-stopped
    networks:
      - chat-app-network

  log-generator:
    build:
      context: ./apps/logs-producer
      dockerfile: Dockerfile
    container_name: log-generator
    restart: unless-stopped
    volumes:
      - log_data:/app/synthetic_logs # This should match your Go code's output path
    networks:
      - chat-app-network
    environment:
      - LOG_OUTPUT_DIR=/app/synthetic_logs # M

  fluent-bit:
    image: fluent/fluent-bit:3.0
    container_name: fluent-bit
    ports:
      - "2020:2020"
    volumes:
      - log_data:/fluent-bit/logs:ro
      - ./apps/fluent-bit-config:/fluent-bit/etc:ro
      - fluent_bit_db:/fluent-bit/db
    environment:
      - HOSTNAME=fluent-bit-container
    depends_on:
      - kafka
      - log-generator
    restart: unless-stopped
    networks:
      - chat-app-network
    command:
      ["/fluent-bit/bin/fluent-bit", "--config=/fluent-bit/etc/fluent-bit.conf"]

volumes:
  redis_data:
    driver: local
  log_data:
    driver: local
  fluent_bit_db:
    driver: local

networks:
  chat-app-network:
    driver: bridge
